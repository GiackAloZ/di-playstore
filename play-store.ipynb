{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GiackAloZ/di-playstore/blob/master/play-store.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8snshbRNS0U"
   },
   "source": [
    "# Progetto di DI - Google Play Store: Category Classification\n",
    "\n",
    "Questo progetto prende in esame un dataset ottenuto dal Google Play Store, dove sono state collezionate le informazioni riguardanti piu' di 10.000 app.\n",
    "\n",
    "Lo scopo del progetto e' quello di utilizzare semplici tecniche di NLP per classificare una app nella sua categoria (eg. Game, Social, Art & Design, etc...) a partire dal suo nome.\n",
    "\n",
    "Ho trovato il dataset su Kaggle ed e' consultabile [qui](https://www.kaggle.com/lava18/google-play-store-apps).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wM3MQyRZdIEg"
   },
   "source": [
    "## Descrizione del problema e analisi esplorativa\n",
    "\n",
    "Si deve realizzare un modello che, dato il nome di una app, la classifichi in base alla sua categoria tra le varie disponibili (eg. Game, Social, Art & Design, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSVM421q6Gf1"
   },
   "source": [
    "Per prima cosa, importiamo le librerie che ci serviranno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6BR-wPFL_3Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow.keras as ks\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIR4HLJQ4Vcx"
   },
   "source": [
    "### Caricamento e pulizia del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jr4Q88umf1UY"
   },
   "source": [
    "Carichiamo i dati dal csv `googleplaystore.csv` sulla repo GitHub come un dataframe pandas e diamo un'occhiata alla sua shape e alle prime 5 righe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9thdCcFBMFZc"
   },
   "outputs": [],
   "source": [
    "apps_data = pd.read_csv(\"https://raw.githubusercontent.com/GiackAloZ/di-playstore/master/data/googleplaystore.csv\")\n",
    "print(apps_data.shape)\n",
    "apps_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEuQARvZgEPb"
   },
   "source": [
    "Ci sono numerose informazioni in questo dataset, ma le colonne che andremo a considerare sono due:\n",
    "\n",
    "- `App`, ovvero i nomi delle app\n",
    "- `Category`, la categoria a cui appartiene ogni app\n",
    "\n",
    "Andiamo a osservare quali possono essere le categorie a cui un'applicazione puo' appartenere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym_AnCNoVfl-"
   },
   "outputs": [],
   "source": [
    "apps_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9f8syFTgp7o"
   },
   "source": [
    "C'e' una categoria che probabilemente e' stata inserita per errore, cioe' la categoria identificata con il nome \"1.9\", perche' ha una sola occorrenza. Andiamo a vedere di cosa si tratta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pmtdhXohU1c"
   },
   "outputs": [],
   "source": [
    "wrong_data = apps_data[apps_data[\"Category\"] == \"1.9\"]\n",
    "wrong_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRa3gHnbhzNM"
   },
   "source": [
    "Sembrerebbe un dato errato, infatti ha tutte le colonne sbagliate o shiftate. Possiamo rimuoverla dal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRADU_rSh9wq"
   },
   "outputs": [],
   "source": [
    "apps_data = apps_data[~apps_data.index.isin(wrong_data.index)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tcIXnuq4k-U"
   },
   "source": [
    "### Analisi esplorativa delle feature utilizzate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWw0B0X3jYUa"
   },
   "source": [
    "Andiamo ora a visualizzare le categorie in un grafico a barre e in un grafico a torta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "assh7K8fjrVF"
   },
   "outputs": [],
   "source": [
    "apps_data[\"Category\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saDDDJgqKlHL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "apps_data[\"Category\"].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-4RxhiPkU-s"
   },
   "source": [
    "Notiamo che le categorie spaziano da molto popolate (eg. FAMILY o GAME) a scarsamente popolate (eg. COMICS o BEAUTY).\n",
    "Questo potrebbe causare problemi di sbilanciamento di classi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfu-iQBRmX2B"
   },
   "source": [
    "Vogliamo ora farci un'idea di come sono fatti i nomi delle app. Per fare cio', andiamo a concatenare tutti i nomi in una string `text` per poi creare una `cloudword` di tutti i nomi delle app in modo da osservare a colpo d'occhio quali sono le parole che compaiono piu' spesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lADhlbGYdJU"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(apps_data[\"App\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PO6mDog2bfkf"
   },
   "outputs": [],
   "source": [
    "wc = wordcloud.WordCloud(\n",
    "    width=800, height=800,\n",
    "    background_color=\"white\", max_words=200\n",
    ").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIUIHBA1bgOa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IE7RIKXrnHnu"
   },
   "source": [
    "Notiamo subito che le parole piu' utilizzate sono quelle che ci potevamo aspettare, come \"App\" o \"Mobile\" oppure anche \"Free\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAmLNljL5DwN"
   },
   "source": [
    "### Correlazione tra categoria di appartenenza e nomi delle app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILIT-yp_5Cix"
   },
   "source": [
    "Andiamo ora a ottenere le top 5 parole per ogni categoria.\n",
    "Per farlo, raggruppiamo il dataset per categoria e concateniamo i nomi delle app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niD6gtwIumvw"
   },
   "outputs": [],
   "source": [
    "names_category = apps_data.groupby(\"Category\")[\"App\"].agg(\" \".join)\n",
    "names_category.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQHCmCWS0HRj"
   },
   "source": [
    "Poi andiamo a contare le frequenze delle parole di ogni categoria in una BagOfWords utilizzando `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5l0iZBX0TjO"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "bow = vect.fit_transform(names_category)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP8WnMIT0aP-"
   },
   "source": [
    "Ok, il `CountVectorizer` ha rilevato 8714 diverse parole. Ora andiamo a ordinarle per frequenza definendo una funzione che ci restituisce le k parole piu' frequenti in una categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VL3xrGq8tj7j"
   },
   "outputs": [],
   "source": [
    "def most_k_freq(cat_freqs, vect, k=1):\n",
    "    word_freqs = [(word, cat_freqs[0, i]) for word, i in vect.vocabulary_.items()]\n",
    "    word_freqs_sorted = sorted(word_freqs, key=lambda x: x[1], reverse=True)\n",
    "    return word_freqs_sorted[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9NbwU0S1O60"
   },
   "source": [
    "Quindi per ogni riga della BagOfWords andiamo ad estrarre le k parole piu' frequenti.\n",
    "Controlliamo stampando la parole piu' frequenti della prima categoria.\n",
    "Ogni elemento della lista `top_words` e' una tupla con (`word`, `frequency`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EdVk0qXo_RT"
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "top_words = [most_k_freq(row, vect, k) for row in bow]\n",
    "print(top_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55iwh-E_1zA6"
   },
   "source": [
    "Mettiamo il risultato in un dataframe, usando un `MultiIndex` per suddividerlo meglio.\n",
    "Per farlo, dobbiamo prima _flattare_ la lista di liste di tuple `top_words` per renderla una lista di liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGrb0tbEz2Tm"
   },
   "outputs": [],
   "source": [
    "top_words_flatten = [[x for y in cat for x in y] for cat in top_words]\n",
    "\n",
    "ranking_labels = np.arange(k) + 1\n",
    "word_labels = [\"word\", \"freq\"]\n",
    "\n",
    "top_words_df = pd.DataFrame(\n",
    "    top_words_flatten, \n",
    "    index=names_category.index,\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [ranking_labels, word_labels], names=[\"ranking\", \"word_freq\"]\n",
    "    )\n",
    ")\n",
    "top_words_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2juz7nNM2yvE"
   },
   "source": [
    "Andiamo a guardare le statistiche aggregate del dataframe appena creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUo5JrdZ2CZD"
   },
   "outputs": [],
   "source": [
    "top_words_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYlc0av73S1S"
   },
   "source": [
    "Vediamo come la media della parola piu' frequente per ogni categoria e' di circa 50, mentre gia' alla 5a la frequenza media e' di circa 20.\n",
    "\n",
    "Questo nota il fatto che i nomi delle app della stessa categoria sono piu' o meno simili tra loro, o comunque hanno dei termini ricorrenti.\n",
    "Quindi, abbiamo una certa correlazione tra categoria della app e nome di essa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXVq6aS55sIC"
   },
   "source": [
    "## Preprocessing, tokenizzazione ed estrazione delle features dai nomi delle app\n",
    "\n",
    "Uno dei passi fondamentali in un problema di NLP e' l'estrazione delle features.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFZ6CqFzGAvx"
   },
   "outputs": [],
   "source": [
    "vect_no_tok = TfidfVectorizer()\n",
    "X_no_tok = vect_no_tok.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect_no_tok.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_q4TgECGGN5"
   },
   "source": [
    "Usando il tokenizer di default, abbiamo 8714 token differenti.\n",
    "\n",
    "Possiamo ridurre un po' il numero di token anche senza cambiare il tokenizer, ma solo togliendo quei token che compaiono meno di 3 volte nei nomi delle app.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRhFNXnR5-Ag"
   },
   "outputs": [],
   "source": [
    "vect_no_tok = TfidfVectorizer(min_df=3)\n",
    "X_no_tok = vect_no_tok.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect_no_tok.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzp0Lp0GFrB9"
   },
   "source": [
    "Gia' togliendo i token con frequenza minore di 3 riduciamo abbondantemente il numero di token da 8714 a 2336 quindi di oltre 3 volte e mezzo.\n",
    "\n",
    "Andiamo ora a provare lo stemming e la lemmatizzazione. Nelle due funzioni filtriamo anche le stepwords considerate tali da `nltk` e consideriamo solo i token che sono alfabetici e che hanno lunghezza maggiore di 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2aDgknjL0Fy"
   },
   "outputs": [],
   "source": [
    "def get_tokens_no_stopwords_alpha(texts):\n",
    "    tokens = nltk.tokenize.word_tokenize(texts)\n",
    "    #token filtering (not stopword and alphabetic)\n",
    "    return {token for token in tokens\n",
    "                  if token not in nltk.corpus.stopwords.words(\"english\")\n",
    "                     and token.isalpha()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLaFVGLU9v21"
   },
   "outputs": [],
   "source": [
    "def tokenizer_stem(app_names):\n",
    "    tokens = get_tokens_no_stopwords_alpha(app_names)\n",
    "    #stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    stemmed_tokens = {stemmer.stem(token) for token in tokens}\n",
    "    #one-char token removal\n",
    "    return [token for token in stemmed_tokens if len(token) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yV8QPoin-yFb"
   },
   "outputs": [],
   "source": [
    "vect_stem = TfidfVectorizer(min_df=3, tokenizer=tokenizer_stem)\n",
    "X_stem = vect_stem.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect_stem.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbnYdK9kEsnB"
   },
   "outputs": [],
   "source": [
    "def tokenizer_lemm(app_names):\n",
    "    tokens = get_tokens_no_stopwords_alpha(app_names)\n",
    "    #lemmatizzazione\n",
    "    lemmatizer = nltk.wordnet.WordNetLemmatizer()\n",
    "    lemmatized_tokens = {lemmatizer.lemmatize(token) for token in tokens}\n",
    "    #one-char token removal\n",
    "    return [token for token in lemmatized_tokens if len(token) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NzjketXFKb4"
   },
   "outputs": [],
   "source": [
    "vect_lemm = TfidfVectorizer(min_df=3, tokenizer=tokenizer_lemm)\n",
    "X_lemm = vect_lemm.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect_lemm.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtsoKtaRIKxk"
   },
   "source": [
    "Non c'e' una grossa differenza usando stemming o lemmatizzazione. Usiamo la lemmatizzazione siccome e', in genere, piu' precisa.\n",
    "\n",
    "Intanto, andiamo a vedere la lunghezza media dei token dopo la lemmatizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TToW4shu-6k5"
   },
   "outputs": [],
   "source": [
    "tokens, indexes = zip(*vect_lemm.vocabulary_.items())\n",
    "tokens_df = pd.DataFrame(tokens, columns=[\"token\"], index=indexes)\n",
    "tokens_df[\"length\"] = tokens_df[\"token\"].map(len)\n",
    "tokens_df[\"length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPgKfa_yKDbV"
   },
   "source": [
    "E' poco superiore a 5 e mezzo, quindi indica che anche se abbiamo usato il lemming, non abbiamo tolto troppo contenuto dalle parole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU9dSpXsLBk2"
   },
   "source": [
    "## Generazione di diversi modelli di learning\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisione train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3OnO1O51qeu"
   },
   "outputs": [],
   "source": [
    "X = apps_data[\"App\"]\n",
    "y = apps_data[\"Category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=1/6,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scelta feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuNKItTDUKAn"
   },
   "outputs": [],
   "source": [
    "vect_lemm = TfidfVectorizer(tokenizer=tokenizer_lemm, min_df=2)\n",
    "X_train_lemm = vect_lemm.fit_transform(X_train)\n",
    "X_test_lemm = vect_lemm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NweuseNE1GoR"
   },
   "outputs": [],
   "source": [
    "param_perceptron = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"alpha\": np.logspace(-5, -2, num=4)\n",
    "}\n",
    "\n",
    "search_perceptron = GridSearchCV(\n",
    "    Perceptron(random_state=42),\n",
    "    param_grid=param_perceptron,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "search_perceptron.fit(X_train_lemm, y_train)\n",
    "search_perceptron.score(X_test_lemm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7XonxQLLAXp"
   },
   "outputs": [],
   "source": [
    "search_perceptron.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulsq_7z2L8fn"
   },
   "outputs": [],
   "source": [
    "param_logistic = [\n",
    "    {\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": np.logspace(-2, 2, num=5)\n",
    "    },\n",
    "    {\n",
    "        \"penalty\": [\"elasticnet\"],\n",
    "        \"C\": np.logspace(-2, 2, num=5),\n",
    "        \"l1_ratio\": [0.1, 0.2, 0.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "search_logistic = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, solver=\"saga\"),\n",
    "    param_grid=param_logistic,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "search_logistic.fit(X_train_lemm, y_train)\n",
    "search_logistic.score(X_test_lemm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_NRzYB6NT4L"
   },
   "outputs": [],
   "source": [
    "search_logistic.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lElWukfvWq_u"
   },
   "outputs": [],
   "source": [
    "param_svc = {\n",
    "    \"gamma\" : [0.1, 1, 5],\n",
    "    \"C\" : [1, 5],\n",
    "    \"kernel\" : ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "search_svc = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid=param_svc,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "search_svc.fit(X_train_lemm, y_train)\n",
    "search_svc.score(X_test_lemm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10D6r0TYU6fy"
   },
   "outputs": [],
   "source": [
    "search_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39m2eFbTWrnb"
   },
   "outputs": [],
   "source": [
    "param_mlp = {\n",
    "    \"hidden_layer_sizes\" : [(size,) for size in np.logspace(4, 8, num=5, base=2).astype(int)],\n",
    "    \"alpha\" : np.logspace(-5, -2, num=4)\n",
    "}\n",
    "\n",
    "search_mlp = GridSearchCV(\n",
    "    MLPClassifier(random_state=42),\n",
    "    param_grid=param_mlp,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "search_mlp.fit(X_train_lemm, y_train)\n",
    "search_mlp.score(X_test_lemm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def keras_model(hidden_layer_sizes=(64,64), reg_rate=1e-4):\n",
    "    model = ks.models.Sequential([\n",
    "        ks.Input(shape=(X_train_lemm.shape[1],))] + [\n",
    "        ks.layers.Dense(size,\n",
    "                        activation=\"relu\",\n",
    "                        kernel_regularizer=ks.regularizers.l2(reg_rate)) for size in hidden_layer_sizes\n",
    "    ] + [ks.layers.Dense(y.unique().size, activation=\"softmax\")]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "keras_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keras = {\n",
    "    \"hidden_layer_sizes\": [(size, size) for size in np.logspace(3, 6, num=4, base=2).astype(int)]\n",
    "    \"reg_rate\": np.logspace(-5, -2, num=4)\n",
    "}\n",
    "\n",
    "keras_model_wrap = KerasClassifier(keras_model)\n",
    "\n",
    "search_keras = GridSearchCV(\n",
    "    keras_model_wrap,\n",
    "    param_grid=param_keras,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "search_keras.fit(X_train_lemm, y_train_encoded, batch_size=128, epochs=10)\n",
    "search_keras.score(X_test_lemm, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keras.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "play-store.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
