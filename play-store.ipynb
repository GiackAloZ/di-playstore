{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GiackAloZ/di-playstore/blob/master/play-store.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Aloisi Giacomo (giacomo.aloisi@studio.unibo.it) Mat 0000832933_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8snshbRNS0U"
   },
   "source": [
    "# Progetto di DI - Google Play Store: Category Classification\n",
    "\n",
    "Questo progetto prende in esame un dataset ottenuto dal Google Play Store, dove sono state collezionate le informazioni riguardanti piu' di 10.000 app.\n",
    "\n",
    "Lo scopo del progetto e' quello di utilizzare semplici tecniche di NLP per classificare una app nella sua categoria (eg. Game, Social, Art & Design, etc...) a partire dal suo nome.\n",
    "\n",
    "Ho trovato il dataset su Kaggle ed e' consultabile [qui](https://www.kaggle.com/lava18/google-play-store-apps).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wM3MQyRZdIEg"
   },
   "source": [
    "## Descrizione del problema e analisi esplorativa\n",
    "\n",
    "Si deve realizzare un modello che, dato il nome di una app, la classifichi in base alla sua categoria tra le varie disponibili (eg. Game, Social, Art & Design, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSVM421q6Gf1"
   },
   "source": [
    "Per prima cosa, importiamo le librerie che ci serviranno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6BR-wPFL_3Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow.keras as ks\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIR4HLJQ4Vcx"
   },
   "source": [
    "### Caricamento e pulizia del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jr4Q88umf1UY"
   },
   "source": [
    "Carichiamo i dati dal csv `googleplaystore.csv` sulla repo GitHub come un dataframe pandas e diamo un'occhiata alla sua shape e alle prime 5 righe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9thdCcFBMFZc"
   },
   "outputs": [],
   "source": [
    "apps_data = pd.read_csv(\"https://raw.githubusercontent.com/GiackAloZ/di-playstore/master/data/googleplaystore.csv\")\n",
    "print(apps_data.shape)\n",
    "apps_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEuQARvZgEPb"
   },
   "source": [
    "Ci sono numerose informazioni in questo dataset, ma le colonne che andremo a considerare sono due:\n",
    "\n",
    "- `App`, ovvero i nomi delle app\n",
    "- `Category`, la categoria a cui appartiene ogni app\n",
    "\n",
    "Andiamo a osservare quali possono essere le categorie a cui un'applicazione puo' appartenere e la loro frequenza nel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym_AnCNoVfl-"
   },
   "outputs": [],
   "source": [
    "apps_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9f8syFTgp7o"
   },
   "source": [
    "C'e' una categoria che probabilemente e' stata inserita per errore, cioe' la categoria identificata con il nome \"1.9\", perche' ha una sola occorrenza. Andiamo a vedere di cosa si tratta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pmtdhXohU1c"
   },
   "outputs": [],
   "source": [
    "wrong_data = apps_data[apps_data[\"Category\"] == \"1.9\"]\n",
    "wrong_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRa3gHnbhzNM"
   },
   "source": [
    "Sembrerebbe un dato errato, infatti ha tutte le colonne sbagliate o shiftate. Possiamo rimuoverla dal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRADU_rSh9wq"
   },
   "outputs": [],
   "source": [
    "apps_data = apps_data[~apps_data.index.isin(wrong_data.index)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tcIXnuq4k-U"
   },
   "source": [
    "### Analisi esplorativa delle feature utilizzate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWw0B0X3jYUa"
   },
   "source": [
    "Andiamo ora a visualizzare le categorie in un grafico a barre e in un grafico a torta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "assh7K8fjrVF"
   },
   "outputs": [],
   "source": [
    "apps_data[\"Category\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saDDDJgqKlHL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "apps_data[\"Category\"].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-4RxhiPkU-s"
   },
   "source": [
    "Notiamo che le categorie spaziano da molto popolate (eg. FAMILY o GAME) a scarsamente popolate (eg. COMICS o BEAUTY).\n",
    "Questo potrebbe causare problemi in fase di addestramento, perche' le classi risultano abbastanza sbilanciate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfu-iQBRmX2B"
   },
   "source": [
    "Vogliamo ora farci un'idea di come sono fatti i nomi delle app. Per fare cio', andiamo a concatenare tutti i nomi in una string `text` per poi creare una `cloudword` di tutti i nomi delle app in modo da osservare a colpo d'occhio quali sono le parole che compaiono piu' spesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lADhlbGYdJU"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(apps_data[\"App\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PO6mDog2bfkf"
   },
   "outputs": [],
   "source": [
    "wc = wordcloud.WordCloud(\n",
    "    width=800, height=800,\n",
    "    background_color=\"white\", max_words=200\n",
    ").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIUIHBA1bgOa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IE7RIKXrnHnu"
   },
   "source": [
    "Notiamo subito che le parole piu' utilizzate sono quelle che ci potevamo aspettare, come \"App\" o \"Mobile\" oppure anche \"Free\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAmLNljL5DwN"
   },
   "source": [
    "### Correlazione tra categoria di appartenenza e nomi delle app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILIT-yp_5Cix"
   },
   "source": [
    "Andiamo ora a ottenere le top 5 parole piu' frequenti per ogni categoria.\n",
    "Per farlo, raggruppiamo il dataset per categoria e concateniamo i nomi delle app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niD6gtwIumvw"
   },
   "outputs": [],
   "source": [
    "names_category = apps_data.groupby(\"Category\")[\"App\"].agg(\" \".join)\n",
    "names_category.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQHCmCWS0HRj"
   },
   "source": [
    "Poi andiamo a contare le frequenze delle parole di ogni categoria in una BagOfWords utilizzando `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5l0iZBX0TjO"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "bow = vect.fit_transform(names_category)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP8WnMIT0aP-"
   },
   "source": [
    "Ok, il `CountVectorizer` ha rilevato 8714 diverse parole. Ora andiamo a ordinarle per frequenza definendo una funzione che ci restituisce le k parole piu' frequenti in una categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VL3xrGq8tj7j"
   },
   "outputs": [],
   "source": [
    "def most_k_freq(cat_freqs, vect, k=1):\n",
    "    word_freqs = [(word, cat_freqs[0, i]) for word, i in vect.vocabulary_.items()]\n",
    "    word_freqs_sorted = sorted(word_freqs, key=lambda x: x[1], reverse=True)\n",
    "    return word_freqs_sorted[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9NbwU0S1O60"
   },
   "source": [
    "Quindi per ogni riga della BagOfWords andiamo ad estrarre le k parole piu' frequenti.\n",
    "Controlliamo stampando la parole piu' frequenti della prima categoria.\n",
    "Ogni elemento della lista `top_words` e' una tupla con (`word`, `frequency`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EdVk0qXo_RT"
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "top_words = [most_k_freq(row, vect, k) for row in bow]\n",
    "print(top_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55iwh-E_1zA6"
   },
   "source": [
    "Mettiamo il risultato in un dataframe, usando un `MultiIndex` per suddividerlo meglio.\n",
    "Per farlo, dobbiamo prima _flattare_ la lista di liste di tuple `top_words` per renderla una lista di liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGrb0tbEz2Tm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_words_flatten = [[x for y in cat for x in y] for cat in top_words]\n",
    "\n",
    "ranking_labels = np.arange(k) + 1\n",
    "word_labels = [\"word\", \"freq\"]\n",
    "\n",
    "top_words_df = pd.DataFrame(\n",
    "    top_words_flatten, \n",
    "    index=names_category.index,\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [ranking_labels, word_labels], names=[\"ranking\", \"word_freq\"]\n",
    "    )\n",
    ")\n",
    "top_words_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo, ad esmpio, che la parola piu' frequente della categoria _ART & DESIGN_ e' \"coloring\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2juz7nNM2yvE"
   },
   "source": [
    "Andiamo a guardare le statistiche aggregate del dataframe appena creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUo5JrdZ2CZD"
   },
   "outputs": [],
   "source": [
    "top_words_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYlc0av73S1S"
   },
   "source": [
    "Vediamo come la media della parola piu' frequente per ogni categoria e' di circa 50, mentre gia' alla 5a la frequenza media e' di circa 20.\n",
    "\n",
    "Questo nota il fatto che i nomi delle app della stessa categoria sono piu' o meno simili tra loro, o comunque hanno dei termini ricorrenti.\n",
    "Quindi, abbiamo una certa correlazione tra categoria della app e nome di essa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXVq6aS55sIC"
   },
   "source": [
    "## Preprocessing, tokenizzazione ed estrazione delle features dai nomi delle app\n",
    "\n",
    "Uno dei passi fondamentali in un problema di NLP e' l'estrazione delle features.\n",
    "\n",
    "Ci sono vari modi per estrarre delle feature dal testo. Si potrebbe procedere con l;utilizzo di un modello booleano per la trasformazione di un testo in vettore booleano, ma si e' preferito usare tecniche **VSM** (vectro space model) per rappresentare il testo.\n",
    "\n",
    "Per questa analisi, si e' deciso di utilizzare come informazione principale la frequenza delle diverse parole nei nomi delle app. Per fare cio', si utilizza una tecnica di conteggio delle frequenze del singolo sample in relazione con le frequenze di tutti i sample, cosi' da ottenere la cosidetta **term frequency-inverse document frequency** (TF-IDF). Usiamo un _transformer_ di _scikit-learn_ che permette di trasformare una sequenza di testi in una rappresentazione vettoriale usando questa tecninca (`TfidfVectorizer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFZ6CqFzGAvx"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tokenized_app_names = vect.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_q4TgECGGN5"
   },
   "source": [
    "Usando il tokenizer di default, abbiamo 8714 token differenti.\n",
    "\n",
    "Possiamo ridurre un po' il numero di token anche senza cambiare il tokenizer, ma solo togliendo quei token che compaiono solo una volta in tutti in nomi delle app. Per farlo, impostiamo il parametro `min_df` (minimum document frequency) pari a 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRhFNXnR5-Ag"
   },
   "outputs": [],
   "source": [
    "vect_min_2 = TfidfVectorizer(min_df=2)\n",
    "tokenized_app_names_min_2 = vect_min_2.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens : {len(vect_min_2.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzp0Lp0GFrB9"
   },
   "source": [
    "Gia' togliendo i token che compaiono solo una volta riduciamo abbondantemente il numero di token da 8714 a 3583 quindi di oltre 2 volte.\n",
    "\n",
    "Andiamo ora a provare lo stemming e la lemmatizzazione. Nelle due funzioni filtriamo anche le stepwords considerate tali dalla libreria `nltk` e consideriamo solo i token che sono alfabetici.\n",
    "\n",
    "**NB**: Si presuppone che la maggior parte del testo nella app sia in lingua inglese. In realta', nel dataset compaiono anche altre lingue, come vedremo piu' tardi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2aDgknjL0Fy"
   },
   "outputs": [],
   "source": [
    "def get_tokens_no_stopwords_alpha(texts):\n",
    "    tokens = nltk.tokenize.word_tokenize(texts)\n",
    "    #token filtering (not stopword and alphabetic)\n",
    "    return {token for token in tokens\n",
    "                  if token not in nltk.corpus.stopwords.words(\"english\")\n",
    "                     and token.isalpha()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLaFVGLU9v21"
   },
   "outputs": [],
   "source": [
    "def tokenizer_stem(app_names):\n",
    "    tokens = get_tokens_no_stopwords_alpha(app_names)\n",
    "    #stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    stemmed_tokens = {stemmer.stem(token) for token in tokens}\n",
    "    #one-char token removal\n",
    "    return [token for token in stemmed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbnYdK9kEsnB"
   },
   "outputs": [],
   "source": [
    "def tokenizer_lemm(app_names):\n",
    "    tokens = get_tokens_no_stopwords_alpha(app_names)\n",
    "    #lemmatizzazione\n",
    "    lemmatizer = nltk.wordnet.WordNetLemmatizer()\n",
    "    lemmatized_tokens = {lemmatizer.lemmatize(token) for token in tokens}\n",
    "    #one-char token removal\n",
    "    return [token for token in lemmatized_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NzjketXFKb4"
   },
   "outputs": [],
   "source": [
    "vect_stem = TfidfVectorizer(min_df=2, tokenizer=tokenizer_stem)\n",
    "tokenized_app_names_stem = vect_stem.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens (stem): {len(vect_stem.get_feature_names())}\")\n",
    "\n",
    "vect_lemm = TfidfVectorizer(min_df=2, tokenizer=tokenizer_lemm)\n",
    "tokenized_app_names_lemm = vect_lemm.fit_transform(apps_data[\"App\"])\n",
    "print(f\"Number of tokens (lem): {len(vect_lemm.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtsoKtaRIKxk"
   },
   "source": [
    "Le feature diminuiscono, ma non significamente. Probabilmente per via del fatto che i nomi delle app sono per lo piu' nomi propri (es. Instagram, Skype, etc...) e contengono poco testo utilizzato normalmente in documenti testuali.\n",
    "\n",
    "Comunque, andiamo a confrontare la lunghezza media dei token prima e dopo lo stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TToW4shu-6k5"
   },
   "outputs": [],
   "source": [
    "token_lengths = pd.Series(map(len, vect_min_2.get_feature_names()))\n",
    "stem_token_lengths = pd.Series(map(len, vect_stem.get_feature_names()))\n",
    "\n",
    "print(f\"Mean length no lemming: {token_lengths.mean():.2f}\")\n",
    "print(f\"Mean length with lemming: {stem_token_lengths.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPgKfa_yKDbV"
   },
   "source": [
    "Sono entrame molto simili, quindi significa che, anche dopo lo stemming, le parole non vengono ridotte troppo in lunghezza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Siccome sia lo stemming che la lemmatizzazione non sono riuscite a ridurre abbastanza lo spazio delle features, si e' deciso, in primo approcio, di non utilizzarle. Successivamente, quando si fara' un'ultima fase di tuning sui modelli piu' promettenti, si provera' anche il loro utilizzo, per vedere quanto incidano sull'accuratezza del modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU9dSpXsLBk2"
   },
   "source": [
    "## Generazione di diversi modelli di learning\n",
    "\n",
    "Si procede con la generazione di diversi modelli di _supervised learning_ per la predizione della categoria dato il nome dell'app. Possiamo dire che il nostro e' un problema di **classificazione multipla**, per cui ho usato alcuni dei possibili modelli utili ad affrontare questo tipo di problemi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAcXLUHAZLiw"
   },
   "source": [
    "### Divisione train e test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si procede andando a selezionare le features dal dataset (nel nostro caso solo una, il nome delle app) e il _target_ della classificazione (cioe' le categorie delle app).\n",
    "\n",
    "Si divide il dataset in _train_ e _test_ set, usando il 90% del dataset come train set e il restante 10% come test set. Nel fare cio', si dividono i dati usando la stratificazione per classe, in modo che le classi siano bilanciate allo stesso modo sia nel train set che nel test set. Questo ci permette di ottenere una misura dell'accuratezza piu' precisa quando si andra' a testare il modello sul test set.\n",
    "\n",
    "**NB**: non viene menzionato il validation set perche' tutta la parte sperimentale di scelta degli iperparametri nei vari modelli viene fatta attraverso _cross-fold validation_ , per cui il validation set viene ogni volta preso come parte del train set. Si noti anche che il test set, una volta diviso, non viene mai usato come parametro del training o della validation per trovare i migliori iperparametri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3OnO1O51qeu"
   },
   "outputs": [],
   "source": [
    "X = apps_data[\"App\"]\n",
    "y = apps_data[\"Category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=1/10,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo quindi 9756 samples dedicati al training, contro 1084 per testare il modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue una lista di modelli, i quali vengono addestrati sul train set usando una _K-cross-fold validation_ stratificata (riduce il bias dato da un training con classi poco distribuite) insieme a una grid-search per trovare i migliori iperparametri per ogni modello.\n",
    "\n",
    "I modelli presi in esame sono:\n",
    "\n",
    "- Perceptron\n",
    "- Regressione logistica\n",
    "- Support-Vector Machine per classificazione (con vari kernel, anche lineari)\n",
    "- Multi-layer Perceptron (con due layer nascosti)\n",
    "- Rete neurale con Keras (con due layer nascosti)\n",
    "\n",
    "Ogni modello viene successivamente testato sul test set, calcolandone l'accuratezza.\n",
    "Vengono anche stampati gli iperparametri che hanno avuto un'accuratezza media migliore nella varie fold di validation.\n",
    "\n",
    "**NB**: in tutti i modelli si utilizza il `TfidVectorizer` come calcolo del VMS con parametro `min_df=2`. Per ogni modello si imposta un `random_state` per rendere riproducibili i risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPTWrAoRZLi2"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NweuseNE1GoR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_perceptron = {\n",
    "    \"perc__penalty\": [\"l1\", \"l2\"],\n",
    "    \"perc__alpha\": np.logspace(-5, -2, num=4)\n",
    "}\n",
    "\n",
    "model_perceptron = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"perc\", Perceptron(random_state=42))\n",
    "])\n",
    "\n",
    "search_perceptron = GridSearchCV(\n",
    "    model_perceptron,\n",
    "    param_grid=param_perceptron,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")\n",
    "search_perceptron.fit(X_train, y_train)\n",
    "scores[\"perceptron\"] = search_perceptron.score(X_test, y_test)\n",
    "scores[\"perceptron\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7XonxQLLAXp"
   },
   "outputs": [],
   "source": [
    "best_params[\"perceptron\"] = search_perceptron.best_params_\n",
    "best_params[\"perceptron\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AknGkGj3ZLi5"
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulsq_7z2L8fn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_logistic = [\n",
    "    {\n",
    "        \"logreg__penalty\": [\"l1\", \"l2\"],\n",
    "        \"logreg__C\": np.logspace(0, 1, num=3)\n",
    "    },\n",
    "    {\n",
    "        \"logreg__penalty\": [\"elasticnet\"],\n",
    "        \"logreg__C\": np.logspace(0, 1, num=3),\n",
    "        \"logreg__l1_ratio\": [0.1, 0.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "model_logistic = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"logreg\", LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\"))\n",
    "])\n",
    "\n",
    "search_logistic = GridSearchCV(\n",
    "    model_logistic,\n",
    "    param_grid=param_logistic,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")\n",
    "search_logistic.fit(X_train, y_train)\n",
    "scores[\"logreg\"] = search_logistic.score(X_test, y_test)\n",
    "scores[\"logreg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_NRzYB6NT4L"
   },
   "outputs": [],
   "source": [
    "best_params[\"logreg\"] = search_logistic.best_params_\n",
    "best_params[\"logreg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search_logistic.cv_results_).sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBZacwo2ZLi_"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lElWukfvWq_u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_svc = [\n",
    "    {\n",
    "        \"svc__gamma\" : [0.1, 1, 5],\n",
    "        \"svc__C\" : [1, 10],\n",
    "        \"svc__kernel\" : [\"rbf\"]\n",
    "    },\n",
    "    {\n",
    "        \"svc__gamma\" : [0.1, 1, 5],\n",
    "        \"svc__C\" : [1, 10],\n",
    "        \"svc__kernel\" : [\"poly\"],\n",
    "        \"svc__degree\": [3, 5]\n",
    "    },\n",
    "    {\n",
    "        \"svc__C\" : [1, 10],\n",
    "        \"svc__kernel\" : [\"linear\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "model_scv = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"svc\", SVC(random_state=42))\n",
    "])\n",
    "\n",
    "search_svc = GridSearchCV(\n",
    "    model_scv,\n",
    "    param_grid=param_svc,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")\n",
    "search_svc.fit(X_train, y_train)\n",
    "scores[\"svc\"] = search_svc.score(X_test, y_test)\n",
    "scores[\"svc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10D6r0TYU6fy"
   },
   "outputs": [],
   "source": [
    "best_params[\"svc\"] = search_svc.best_params_\n",
    "best_params[\"svc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiBepaL1ZLjD"
   },
   "source": [
    "### Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39m2eFbTWrnb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_mlp = {\n",
    "    \"mlp__hidden_layer_sizes\" : [(size, size//2) for size in np.logspace(4, 6, num=3, base=2, dtype=np.int)],\n",
    "    \"mlp__alpha\" : np.logspace(-3, -1, num=3)\n",
    "}\n",
    "\n",
    "model_mlp = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"mlp\", MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "search_mlp = GridSearchCV(\n",
    "    model_mlp,\n",
    "    param_grid=param_mlp,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")\n",
    "search_mlp.fit(X_train, y_train)\n",
    "scores[\"mlp\"] = search_mlp.score(X_test, y_test)\n",
    "scores[\"mlp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jalN-MlFtjwm"
   },
   "outputs": [],
   "source": [
    "best_params[\"mlp\"] = search_mlp.best_params_\n",
    "best_params[\"mlp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0Xu4ozGZLjG"
   },
   "source": [
    "### Keras neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUdaIKc01EKN"
   },
   "outputs": [],
   "source": [
    "class KerasModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,\n",
    "                 hidden_layer_sizes=(64,64),\n",
    "                 reg_rate=1e-4,\n",
    "                 epochs=20,\n",
    "                 batch_size=64):\n",
    "        # label encoder (string -> int)\n",
    "        self._encoder = LabelEncoder()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.reg_rate = reg_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y, **kargs):\n",
    "        # encode string classes to integers\n",
    "        y_encoded = self._encoder.fit_transform(y)\n",
    "\n",
    "        # keras model with multiple hidden layers with \"relu\" activation\n",
    "        # and one final layer with \"softmax\" activation for mutli-class classification\n",
    "        self._model = ks.models.Sequential([\n",
    "            ks.Input(shape=X.shape[1:2])] + [     # input layer with shape equal to number of classes \n",
    "            ks.layers.Dense(size,\n",
    "                            activation=\"relu\",    # ReLU activation and weights L2 regularization\n",
    "                            kernel_regularizer=ks.regularizers.l2(self.reg_rate)) for size in self.hidden_layer_sizes\n",
    "            ] + [ks.layers.Dense(self._encoder.classes_.size, activation=\"softmax\")]   # output layer proba\n",
    "        )\n",
    "        \n",
    "        self._model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"acc\"]\n",
    "        )\n",
    "\n",
    "        # show only epoch number while fitting\n",
    "        self._model.fit(X.toarray(), y_encoded, batch_size=self.batch_size, epochs=self.epochs, verbose=0, **kargs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self._model.predict_classes(X.toarray())\n",
    "        # inverse transform classes (int -> string)\n",
    "        return self._encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPC_SwBpZLjK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_keras = {\n",
    "    \"keras__hidden_layer_sizes\": [(size, size) for size in np.logspace(4, 6, num=3, base=2, dtype=np.int)],\n",
    "    \"keras__reg_rate\": np.logspace(-4, -2, num=3),\n",
    "    \"keras__batch_size\": np.logspace(8, 10, num=3, base=2, dtype=np.int),\n",
    "    \"keras__epochs\": [20, 50]\n",
    "}\n",
    "\n",
    "model_keras = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"keras\", KerasModel())\n",
    "])\n",
    "\n",
    "search_keras = GridSearchCV(\n",
    "    model_keras,\n",
    "    param_grid=param_keras,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2\n",
    ")\n",
    "search_keras.fit(X_train, y_train)\n",
    "scores[\"keras\"] = search_keras.score(X_test, y_test)\n",
    "scores[\"keras\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params[\"keras\"] = search_keras.best_params_\n",
    "best_params[\"keras\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scelta dei modelli migliori e fine tuning\n",
    "\n",
    "Vediamo ora le performance di tutti i modelli che sono stati addestrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame([[score for _, score in scores.items()]], index=scores.keys(), columns=[\"accuracy\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, la `LogisticRegression` e il modello `SVC` sono i due che hanno un'accuratezza piu' alta del resto dei modelli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning dei migliori due modelli\n",
    "\n",
    "Andiamo ora a fare un po' di _fine tuning_ dei due modelli migliori. Proviamo stemming e lemmatizzazione, inoltre introduciamo anche la possibilita' di considerare _n-grammi_ di lunghezza due per il calcolo del TF-IDF.\n",
    "\n",
    "Vediamo i risultati della cross validation di entrambi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search_logistic.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search_svc.cv_results_).sort_values(\"mean_test_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la `LogisticRegression` usiamo sempre la regolarizzazione _ridge_ (l2) che, insieme a _elasticnet_ , sembra dare i migliori risultati, ma a differenza di _elasticnet_ e' piu' veloce nel training.\n",
    "Per il `SVC` usiamo il kernel `rbf` per lo stesso motivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ft = {}\n",
    "best_params_ft = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_logistic = {\n",
    "    \"vect__tokenizer\": [None, tokenizer_lemm, tokenizer_stem],\n",
    "    \"vect__ngram_range\": [(1,1), (1,2)],\n",
    "    \"logreg__C\": np.logspace(1,1, num=1)\n",
    "}\n",
    "\n",
    "model_logistic = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"logreg\", LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\", penalty=\"l2\"))\n",
    "])\n",
    "\n",
    "search_logistic = GridSearchCV(\n",
    "    model_logistic,\n",
    "    param_grid=param_logistic,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2\n",
    ")\n",
    "search_logistic.fit(X_train, y_train)\n",
    "scores_ft[\"logreg\"] = search_logistic.score(X_test, y_test)\n",
    "scores_ft[\"logreg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ft[\"logreg\"] = search_logistic.best_params_\n",
    "best_params_ft[\"logreg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_svc = {\n",
    "    \"vect__tokenizer\": [None, tokenizer_lemm, tokenizer_stem],\n",
    "    \"vect__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"svc__gamma\" : np.logspace(-2, 0, num=5),\n",
    "}\n",
    "\n",
    "model_scv = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(min_df=2)),\n",
    "    (\"svc\", SVC(random_state=42, C=10, kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "search_svc = GridSearchCV(\n",
    "    model_scv,\n",
    "    param_grid=param_svc,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")\n",
    "search_svc.fit(X_train, y_train)\n",
    "search_svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricontrolliamo le performance dei due modelli scelti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ft_df = pd.DataFrame([[score for _, score in scores_ft.items()]], index=scores_ft.keys(), columns=[\"accuracy\"])\n",
    "scores_ft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMRPmc0XZLjS"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Prendiamo il modello `LogistiRegression` per valutarllo un po' piu' nello specifico. In particolare, vorremo sapere informazioni sui coefficenti delle varie parole, ovvero i pesi del modello.\n",
    "\n",
    "Come si relazionano i vari coefficenti delle parole con le classi da predirre?\n",
    "Creiamo un dataframe che metta in relazione le classi con i coefficenti delle parole. In particolare, ogni cella del dataframe avra', come intersezione di classe e parola, il peso che quella parola ha per quella particolare classe.\n",
    "\n",
    "Il peso e' il coefficente di correlazione tra la parola e la classe (positivo -> correlazione alta diretta, negativo -> correlazione alta inversa, zero -> poca o nessuna correlazione)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = search_logistic.best_estimator_\n",
    "coeffs_df = pd.DataFrame(\n",
    "    model_logistic.named_steps[\"logreg\"].coef_,\n",
    "    index=model_logistic.named_steps[\"logreg\"].classes_,\n",
    "    columns=model_logistic.named_steps[\"vect\"].get_feature_names())\n",
    "coeffs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo, ad esempio, i coefficenti delle parole \"calculator\" e \"flashlight\" rispettivamente nelle classi \"PRODUCTIVITY\" e \"GAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_df.loc[\"PRODUCTIVITY\", \"calculator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_df.loc[\"GAME\", \"flashlight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si poteva immaginare, \"calculator\" e' positivamente correlata con \"PRODUCTIVITY\", il che significa che si un'applicazione ha nel suo nome la parola \"calculator\" e' probabile che sia appartenga alla classe \"PRODUCTIVITY\".\n",
    "\n",
    "Viceversa, siccome \"flashlight\" e' negativamente correlata con \"GAME\", difficilmente un'applicazione che contiene questa parola verra' etichettata come \"GAME\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo ora a mostrare, per ogni classe, la parola con coefficente piu' alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_coeffs_df = pd.concat([coeffs_df.idxmax(axis=1), coeffs_df.max(axis=1)], axis=1)\n",
    "best_coeffs_df.columns = [\"word\", \"coeff\"]\n",
    "best_coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo ora la **matrice di confusione**, che e' stata normalizzata e plottata come _heatmap_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model_logistic.predict(X_test)\n",
    "conf_logistic = confusion_matrix(y_test, y_pred)\n",
    "conf_logistic = conf_logistic / conf_logistic.sum(axis=1)\n",
    "sns.heatmap(conf_logistic, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per capire meglio quanto il modello sia preciso rispettivamante ad ogni classe, andiamo a stampare il `classification report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraiamo dal report le classi con le migliori e le peggiori precisioni, recall e f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T\n",
    "logistic_report_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_report_df.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo ora tutte e quattro le metriche principali delle classificazione (accuratezza, precisione, recall e f1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc_prec_rec_f1(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred, normalize=True)\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = calc_acc_prec_rec_f1(y_test, y_pred)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamolo per ogni modello e costruiamo un dataframe con i risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchs = [\n",
    "    (\"perceptron\", search_perceptron),\n",
    "    (\"logreg\", search_logistic),\n",
    "    (\"svc\", search_svc),\n",
    "    (\"mlp\", search_mlp),\n",
    "    (\"keras\", search_keras)\n",
    "]\n",
    "\n",
    "models = [(name, gs.best_estimator) for name, gs in searchs]\n",
    "\n",
    "metrics = [\n",
    "    calc_acc_prec_rec_f1(model.predict(X_test), y_test) for _, model in models\n",
    "]\n",
    "\n",
    "names = [\n",
    "    name for name, _ in models\n",
    "]\n",
    "\n",
    "model_metrics_df = pd.DataFrame(metrics, index=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo i range delle accuratezze per ogni modello con una confidenza del 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBn8nsKaZLjS"
   },
   "outputs": [],
   "source": [
    "def confidence(acc, N, Z):\n",
    "    den = (2*(N+Z**2))\n",
    "    var = (Z*np.sqrt(Z**2+4*N*acc-4*N*acc**2)) / den\n",
    "    a = (2*N*acc+Z**2) / den\n",
    "    inf = a - var\n",
    "    sup = a + var\n",
    "    return (inf, sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_df[\"accuracy\"].map(lambda acc: confidence(acc, len(y_test), 1.96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGdNBUZAZLjU"
   },
   "outputs": [],
   "source": [
    "confidence(metrics_dict[\"accuracy\"], len(X_test), 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_prediction(X):\n",
    "    return random.choices(model_logistic.classes_, k=len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_random_pred = random_prediction(X_test)\n",
    "random_acc = accuracy_score(y_test, y_random_pred)\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUj0jWKBZLjX"
   },
   "outputs": [],
   "source": [
    "def compare_confidence(acc1, acc2, N, Z):\n",
    "    var_sq = acc1 * (1 - acc1) / N + acc2 * (1 - acc2) / N\n",
    "    a = abs(acc1 - acc2)\n",
    "    inf = a - Z * np.sqrt(var_sq)\n",
    "    sup = a + Z * np.sqrt(var_sq)\n",
    "    return (inf, sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yfd9NBGsKUsJ"
   },
   "outputs": [],
   "source": [
    "compare_confidence(random_acc, metrics_dict[\"accuracy\"], len(X_test), 2.56)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "play-store.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
